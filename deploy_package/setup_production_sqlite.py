#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è SQLite –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞
–° –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π, –∏–Ω–¥–µ–∫—Å–∞–º–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
"""

import sqlite3
import os
import shutil
import logging
from datetime import datetime
from pathlib import Path

class ProductionSQLiteManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä SQLite –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
        self.logger = logging.getLogger(__name__)
        
    def optimize_database(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            # –í–∫–ª—é—á–∞–µ–º WAL —Ä–µ–∂–∏–º –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            cursor.execute("PRAGMA journal_mode=WAL")
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
            cursor.execute("PRAGMA cache_size=10000")
            
            # –í–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—á–∏—Å—Ç–∫—É
            cursor.execute("PRAGMA auto_vacuum=INCREMENTAL")
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å
            cursor.execute("PRAGMA temp_store=MEMORY")
            
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º —Ä–µ–∂–∏–º–µ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
            cursor.execute("PRAGMA synchronous=NORMAL")
            
            # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_access_logs_timestamp_employee ON access_logs(timestamp, employee_id)",
                "CREATE INDEX IF NOT EXISTS idx_access_logs_date_door ON access_logs(DATE(timestamp), door_location)",
                "CREATE INDEX IF NOT EXISTS idx_daily_summary_date_employee ON daily_summary(work_date, employee_id)",
                "CREATE INDEX IF NOT EXISTS idx_lunch_breaks_date_employee ON lunch_breaks(work_date, employee_id)",
                "CREATE INDEX IF NOT EXISTS idx_employees_name ON employees(full_name)",
                "CREATE INDEX IF NOT EXISTS idx_files_metadata_filename ON files_metadata(filename)",
            ]
            
            for index_sql in indexes:
                cursor.execute(index_sql)
                
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
            cursor.execute("ANALYZE")
            
            conn.commit()
            self.logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
        finally:
            conn.close()
    
    def create_backup(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"skud_backup_{timestamp}.db"
        backup_path = self.backup_dir / backup_name
        
        try:
            shutil.copy2(self.db_path, backup_path)
            self.logger.info(f"–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
            backups = sorted(self.backup_dir.glob("skud_backup_*.db"))
            if len(backups) > 10:
                for old_backup in backups[:-10]:
                    old_backup.unlink()
                    self.logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {old_backup}")
                    
            return backup_path
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            return None
    
    def get_database_stats(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            stats = {}
            
            # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            stats['file_size_mb'] = os.path.getsize(self.db_path) / (1024 * 1024)
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
            cursor.execute("PRAGMA page_count")
            stats['page_count'] = cursor.fetchone()[0]
            
            # –†–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            cursor.execute("PRAGMA page_size")
            stats['page_size'] = cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–∞–±–ª–∏—Ü
            tables = ['employees', 'access_logs', 'daily_summary', 'lunch_breaks', 'files_metadata']
            
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                stats[f'{table}_count'] = cursor.fetchone()[0]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º –∂—É—Ä–Ω–∞–ª–∞
            cursor.execute("PRAGMA journal_mode")
            stats['journal_mode'] = cursor.fetchone()[0]
            
            return stats
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
        finally:
            conn.close()
    
    def vacuum_database(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—á–∏—Å—Ç–∫—É –∏ –¥–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É
            conn.execute("PRAGMA incremental_vacuum")
            
            # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)
            conn.execute("VACUUM")
            
            conn.close()
            self.logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞ –∏ –¥–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")

def setup_production_sqlite():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç SQLite –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"""
    
    print("üè≠ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ SQLite –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    print("=" * 60)
    
    db_path = "real_skud_data.db"
    
    if not os.path.exists(db_path):
        print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        return
    
    manager = ProductionSQLiteManager(db_path)
    
    # –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø –ø–µ—Ä–µ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    print("üì¶ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏...")
    backup_path = manager.create_backup()
    if backup_path:
        print(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_path}")
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    print("‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    manager.optimize_database()
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:")
    stats = manager.get_database_stats()
    
    for key, value in stats.items():
        if 'size_mb' in key:
            print(f"   {key}: {value:.2f} MB")
        elif 'count' in key:
            print(f"   {key}: {value:,}")
        else:
            print(f"   {key}: {value}")
    
    # –û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    print("üßπ –û—á–∏—Å—Ç–∫–∞ –∏ –¥–µ—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ü–∏—è...")
    manager.vacuum_database()
    
    print("\n‚úÖ SQLite –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞!")
    print("\nüìã –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("   1. –†–µ–≥—É–ª—è—Ä–Ω–æ —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏")
    print("   2. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    print("   3. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–π—Ç–µ –æ—á–∏—Å—Ç–∫—É")
    print("   4. –î–ª—è –≤—ã—Å–æ–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ PostgreSQL")

if __name__ == "__main__":
    setup_production_sqlite()